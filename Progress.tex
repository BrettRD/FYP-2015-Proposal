\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color}
\title{Hexacopter\\
	Progress Report}
\author{Brett Downing}
\date{}
\begin{document}
  \maketitle

  Progress Report
  
  Accurate judgement of progress to date and plan of further progress.

  \section{Preamble}
    %Buzzword Bingo
    Multicopters are increasingly popular... Simplicity... Market Saturation... rapidly changing legal situation... 
    Recent Developments in power and control electronics.

    Much of the technology related to multicopters is applicable to most other forms of UAV.
    Agriculture, targeted crop dusting
    Mapping
    Cinematography, extreme-sport photography, 


  \section{Where we started}
    The Hexacopter is a DJI F550 frame with fancy-pants motors and ESCs
    The 2013 team  decided to use a NAZA-V1-lite flight computer. This works well for free-flight, but does not make provisions for way-point navigation or telemetry.
    The on-board server is currently doing all of the autonomous navigation processing which is appropriate for computer-vision directed flight-modes, but adds additional  hurdles to way-point navigation; a problem that is already very well-solved in industrial, hobbyist, and consumer grade drones.



  \section{What we've achieved}
    We've implemented and tested the code that we were able to salvage from the previous year-groups,
    Mathematics that estimates the location of a point of interest based on certain assumptions

    We've made a proposal and ordered parts to move to the Ardupilot flight control software running on the Pixhawk flight computer.
    This move allows us to utilise the vast array of supporting software that the Ardpilot community has written including ground-stations, telemetry loggers, Smart-phone apps, Kalman navigation filters and automatic flight control tuning.

    Oddly, our tests of the previous year-groups' code have produced better results than are published in the respective papers, however the claims of the previous groups still appear grossly overstated.
    Various improvements to the hardware including landing gear, Wiring harness, enclosures

    Reverse-engineering of circuits used by the previous groups. Having talked to the previous teams, we appear to have generated better documentation about the hardware than the teams had worked with initially.


  \section{What we intend to do}
    Object Tracking, chase-cam
    position estimation

    \subsection{Lost and Found}
      The copter is already beginning to exhibit strong tracking behaviour but given our problems with N-th order stability, we've not been able to apply aggressive parameter to the chase algorithm.  The tracked object frequently leaves the field of view of the camera.
      We intend to write a series of algorithms to construct a weighted search-space based on the previous motion of the target.  This extrapolation will require some kind of prediction engine incorporating known properties of the target's possible motion. 


  \section{Major Challenges}
    \subsection{Steady Cam}
      As the platform stands, The gimbal does not sufficiently isolate platform motion to stabilise a simple control loop.
      For example, a forward motion instruction from the chase algorithm causes the copter's rear rotors to throttle up, then the platform pitches forward, then the copter accelerates forward.  The pitch data is sent to the camera stabilisation servo which has a slow slew rate and a small delay time.  This delay couples pitch motion into the image processing loop and adds a brief but intense upward swing to the location of the target in the image as the copter accelerates.
      This behaviour is controlled by the physical properties of the copter, the flight-computer's control loops, the servo's controller and the shutter lag on the camera. While all of this is technically possible to compensate for, calibrating against mechanical and electrical properties of a commodity servo and reverse-engineering a third-order control loop introduces a large number of variables and doesn't lend itself easily to empirical validation.
      It makes more sense to solve single whole problems; either cleanly stabilising the camera with a higher performance gimbal, or applying software image stabilisation using motion data from the flight controller to calculate through bulk motions followed by optical flow methods to remove the remaining jitter.

    










	
\end{document}

